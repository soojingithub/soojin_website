<!DOCTYPE html><!--  This site was created in Webflow. https://webflow.com  --><!--  Last Published: Tue Jul 30 2024 15:22:24 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="645129ffb9cf3d44d320fec5" data-wf-site="61d8ff5e7050560d28f3e298">
<head>
  <meta charset="utf-8">
  <title>Elephant in the Room</title>
  <meta content="Elephant in the Room" property="og:title">
  <meta content="Elephant in the Room" property="twitter:title">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="../css/normalize.css" rel="stylesheet" type="text/css">
  <link href="../css/webflow.css" rel="stylesheet" type="text/css">
  <link href="../css/soojinleedesign.webflow.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic","Varela Round:400","Great Vibes:400","Jaldi:regular","Inter:100,200,300,regular,500,600,700,800,900"]  }});</script>
  <script src="https://use.typekit.net/nnu5all.js" type="text/javascript"></script>
  <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="../images/favicon.png" rel="shortcut icon" type="image/x-icon">
  <link href="../images/webclip.png" rel="apple-touch-icon">
</head>
<body>
  <div class="user-testing">
    <div data-collapse="medium" data-animation="default" data-duration="400" data-easing="ease" data-easing2="ease" role="banner" class="navigation w-nav">
      <div class="navigation-items">
        <a href="../index.html" class="link-block w-inline-block"><img src="../images/soojinleeblack.png" width="8" height="8" sizes="(max-width: 991px) 5vw, (max-width: 1279px) 4vw, 3vw" alt="" srcset="../images/soojinleeblack-p-500.png 500w, ../images/soojinleeblack-p-800.png 800w, ../images/soojinleeblack-p-1080.png 1080w, ../images/soojinleeblack-p-1600.png 1600w, ../images/soojinleeblack-p-2000.png 2000w, ../images/soojinleeblack-p-2600.png 2600w, ../images/soojinleeblack.png 3601w" class="logo-image"></a>
        <div class="navigation-wrap">
          <nav role="navigation" class="navigation-items w-nav-menu">
            <a href="../project.html" class="navigation-item w-nav-link">projects</a>
            <a href="../about.html" class="navigation-item w-nav-link">About</a>
            <a href="../documents/Soojin_Resume.pdf" id="playpage" target="_blank" class="navigation-item w-nav-link">RESUME</a>
          </nav>
          <div class="menu-button w-nav-button"><img src="../images/Menu.png" width="22" alt="" class="menu-icon"></div>
        </div>
      </div>
    </div><img src="../images/Elephant-in-the-room.jpg" loading="lazy" sizes="94vw" srcset="../images/Elephant-in-the-room-p-500.jpg 500w, ../images/Elephant-in-the-room-p-800.jpg 800w, ../images/Elephant-in-the-room-p-1080.jpg 1080w, ../images/Elephant-in-the-room-p-1600.jpg 1600w, ../images/Elephant-in-the-room-p-2000.jpg 2000w, ../images/Elephant-in-the-room-p-2600.jpg 2600w, ../images/Elephant-in-the-room-p-3200.jpg 3200w, ../images/Elephant-in-the-room.jpg 3871w" alt="" class="image-20">
  </div>
  <div class="div-block-19">
    <div class="div-block-17">
      <div class="heading-jumbo-tiny">overview</div>
      <p class="paragraph-2 unique">Elephant in the Room is a creative application of LLM technology to modern video consumption. Featuring an AI-driven video dialogue system powered by OpenAI’s GPT-3, it turns passive viewing into interactive conversation. The platform provides a safe space for users 
        to ask questions about intimate topics such as childbirth, sex, and death, free from judgment. Engage in meaningful, 
        perspective-expanding dialogues with pre-recorded videos of others.</p>
      <a href="https://youtu.be/4EK19DnM4_c" target="_blank" class="button-6 w-button">Video Demo</a>
      <a href="https://www.notion.so/Elephant-in-the-Room-45a96d4d30a54e73b9df9f7a4efcb549?pvs=4" class="button-5 w-button">Documentation</a>
    </div>
    <div class="div-block-18">
      <div id="w-node-e1696d2e-41e0-ca88-4d5e-6faf726452de-d320fec5">
        <div class="text-block-8-copy">Project Type</div>
        <div class="text-block-9">Capstone Project<br>Interactive Installation<br>Video Dialogue App<br>‍</div>
      </div>
      <div id="w-node-e1696d2e-41e0-ca88-4d5e-6faf726452e5-d320fec5">
        <div class="text-block-8-copy">Link</div>
        <div class="text-block-9 link">
          <a href="https://docs.google.com/document/d/1WF_yEnLXFutKrTxQYw6aCwQSejngYYl8JaaL6mrBoeo/edit?usp=sharing" target="_blank" class="link">Thesis Paper</a><br>
          <a href="https://www.figma.com/proto/AGo5xG5mpnbi7yLJSkinhv/Soojin-Capstone-Presentation?page-id=0%3A1&amp;node-id=62-100&amp;viewport=320%2C821%2C0.15&amp;scaling=scale-down&amp;starting-point-node-id=62%3A100" target="_blank" class="link">Presentation</a><br>
          <a href="https://www.notion.so/Elephant-in-the-Room-45a96d4d30a54e73b9df9f7a4efcb549?pvs=4" target="_blank" class="link">Notion Document<br></a>
          <a href="https://youtu.be/4EK19DnM4_c" target="_blank">Video Demo</a>
        </div>
      </div>
      <div id="w-node-e1696d2e-41e0-ca88-4d5e-6faf726452f0-d320fec5">
        <div class="text-block-8-copy">Skills</div>
        <div class="text-block-9">Machine Learning<br>Human-Computer-Interaction<br>UX/UI Design<br>Web Development</div>
      </div>
      <div id="w-node-e1696d2e-41e0-ca88-4d5e-6faf726452f5-d320fec5">
        <div class="text-block-8-copy">Duration</div>
        <div class="text-block-9">12 months<br>Apr 2022 - Apr 2023</div>
      </div>
    </div>
  </div><img src="../images/Screenshot-2023-04-25-at-2.03.22-PM.png" loading="lazy" sizes="100vw" width="1281" alt="" srcset="../images/Screenshot-2023-04-25-at-2.03.22-PM-p-500.png 500w, ../images/Screenshot-2023-04-25-at-2.03.22-PM-p-800.png 800w, ../images/Screenshot-2023-04-25-at-2.03.22-PM-p-1080.png 1080w, ../images/Screenshot-2023-04-25-at-2.03.22-PM-p-1600.png 1600w, ../images/Screenshot-2023-04-25-at-2.03.22-PM.png 1814w" class="image-75 wide">
  <div class="div-block-45 eitr">
    <div class="problem challenge-solution this-one project-calll">
      <div class="div-block-48">
        <div class="text-block-28 very-special">FINAL INTERFACE</div>
        <p class="paragraph-2 solution">Users can select the topic they wish to interact with and have a conversation with the recordings via voice or text input. </p>
      </div>
    </div><img src="../images/Group-193.jpg" loading="lazy" sizes="90vw" srcset="../images/Group-193-p-500.jpg 500w, ../images/Group-193-p-800.jpg 800w, ../images/Group-193-p-1080.jpg 1080w, ../images/Group-193-p-1600.jpg 1600w, ../images/Group-193-p-2000.jpg 2000w, ../images/Group-193-p-2600.jpg 2600w, ../images/Group-193.jpg 2958w" alt="" class="image-76">
  </div>
  <div class="challenge solution">
    <div class="heading-jumbo-tiny">motivation <br>‍<br>‍</div>
    <div class="div-block-48 context">
      <div class="text-block-28">Context</div>
      <p class="paragraph-2 solution">How does one come to accept death? How has your body changed after giving birth? It is ironic that some of the most fundamental and universal human experiences, such as birth, death, and sex, are often shied away from and seldom discussed. Despite living in a hyper-connected world, we still struggle to find the right person to talk to about some of the most intimate and important topics. Even with the ability to share information and perspectives beyond physical boundaries thanks to Google and YouTube, the interaction is often distant, one-sided, and unempathetic, leaving us with unsatisfying answers.</p>
    </div>
  </div>
  <div class="challenge solution">
    <div class="heading-jumbo-tiny">Inspirations <br>‍<br>‍</div><img src="../images/Group-194.jpg" loading="lazy" sizes="(max-width: 7075px) 80vw, 5660px" srcset="../images/Group-194-p-500.jpg 500w, ../images/Group-194-p-800.jpg 800w, ../images/Group-194-p-1080.jpg 1080w, ../images/Group-194-p-1600.jpg 1600w, ../images/Group-194-p-2000.jpg 2000w, ../images/Group-194-p-2600.jpg 2600w, ../images/Group-194-p-3200.jpg 3200w, ../images/Group-194.jpg 5660w" alt="">
    <p class="paragraph-7">The Elephant in the Room was inspired by various types of new media artworks and even commercial products. For example, Dimension in Testimony is an interactive biography of genocide survivors installed at the Dallas Holocaust Museum that showed me the potential of immersive video technology. Additionally, the video installation Are You Online Now? by !Mediengruppe Bitnik demonstrated how artificial intelligence can facilitate empathetic human conversations that involve humor, sarcasm, and intricate emotions. Furthermore, the purpose-driven card game We&#x27;re Not Really Strangers emphasizes the importance of breaking down conversation barriers and engaging in conversations outside of one&#x27;s comfort zone.</p>
  </div>
  <div class="challenge solution special">
    <div class="heading-jumbo-tiny">technical choice<br>‍<br>‍</div>
    <div class="div-block-52">
      <div class="div-block-48">
        <div class="text-block-28">TOIA</div>
        <p class="paragraph-2 solution">Time Offset Interaction Application (TOIA), developed by NYU CAMeL Lab, is an open-source web application that offers similar interactions to Testimony of the Holocaust. However, it allows anyone online to interact with pre-recorded videos of people and even create their own avatars. On the left, you can see me recording and creating an avatar. On the right, you can see me interacting with the video avatar of myself. You can try it out <a href="http://34.77.217.30:3001/">here</a>.</p>
      </div><img src="../images/Group-195.jpg" loading="lazy" sizes="(max-width: 4355px) 80vw, 3484px" srcset="../images/Group-195-p-500.jpg 500w, ../images/Group-195-p-800.jpg 800w, ../images/Group-195-p-1080.jpg 1080w, ../images/Group-195-p-1600.jpg 1600w, ../images/Group-195-p-2000.jpg 2000w, ../images/Group-195-p-2600.jpg 2600w, ../images/Group-195-p-3200.jpg 3200w, ../images/Group-195.jpg 3484w" alt="">
    </div>
  </div>
  <div class="challenge solution makeshort">
    <div class="heading-jumbo-tiny">PROOF OF CONCEPT<br>‍<br>‍</div>
    <div class="div-block-53">
      <div class="div-block-48">
        <div class="text-block-28">Elon Musk Avatar</div>
        <p class="paragraph-2 solution">Initially, I had the idea of creating a tool that enables people to communicate with those outside their immediate social circles, including celebrities. As a proof of concept, I transformed an hour-long Ted Talk interview of Elon Musk into an interactive video avatar. This avatar allows users to engage in a conversation with pre-recorded videos of Elon. For instance, when I asked, &quot;Hey Elon, do you have any advice for me?&quot; the video interface returned a pre-recordings of Elon saying, &quot;Try to be useful. It&#x27;s hard to be useful.&quot;</p>
      </div>
      <div class="div-block-49"><img src="../images/Rectangle-1.png" loading="lazy" sizes="(max-width: 991px) 80vw, 64vw" srcset="../images/Rectangle-1-p-500.png 500w, ../images/Rectangle-1-p-800.png 800w, ../images/Rectangle-1-p-1080.png 1080w, ../images/Rectangle-1-p-1600.png 1600w, ../images/Rectangle-1-p-2000.png 2000w, ../images/Rectangle-1-p-2600.png 2600w, ../images/Rectangle-1-p-3200.png 3200w, ../images/Rectangle-1.png 3228w" alt="" class="image-37 elon-musk"></div>
    </div>
    <div class="div-block-53">
      <div class="div-block-48">
        <div class="text-block-28">Technical Process</div>
        <div>
          <p class="paragraph-2 solution tech-process">Wrote a script that uses the Pytube API to download videos and their transcriptions from YouTube.</p><img src="../images/Screenshot-2023-04-29-at-9.17-1.png" loading="lazy" width="507" sizes="(max-width: 479px) 62vw, (max-width: 991px) 57vw, 507px" alt="" srcset="../images/Screenshot-2023-04-29-at-9.17-1-p-500.png 500w, ../images/Screenshot-2023-04-29-at-9.17-1-p-800.png 800w, ../images/Screenshot-2023-04-29-at-9.17-1-p-1080.png 1080w, ../images/Screenshot-2023-04-29-at-9.17-1-p-1600.png 1600w, ../images/Screenshot-2023-04-29-at-9.17-1-p-2000.png 2000w, ../images/Screenshot-2023-04-29-at-9.17-1-p-2600.png 2600w, ../images/Screenshot-2023-04-29-at-9.17-1.png 3000w" class="image-77">
          <p class="paragraph-2 solution tech-process">Trimmed and edited the video using the Davinci Resolve video editor to create shorter, &quot;answerable&quot; clips.</p><img src="../images/Screenshot-2023-04-29-at-9.23-1.jpg" loading="lazy" width="507" sizes="(max-width: 479px) 62vw, (max-width: 991px) 57vw, 507px" alt="" srcset="../images/Screenshot-2023-04-29-at-9.23-1-p-500.jpg 500w, ../images/Screenshot-2023-04-29-at-9.23-1-p-800.jpg 800w, ../images/Screenshot-2023-04-29-at-9.23-1-p-1080.jpg 1080w, ../images/Screenshot-2023-04-29-at-9.23-1-p-1600.jpg 1600w, ../images/Screenshot-2023-04-29-at-9.23-1-p-2000.jpg 2000w, ../images/Screenshot-2023-04-29-at-9.23-1-p-2600.jpg 2600w, ../images/Screenshot-2023-04-29-at-9.23-1.jpg 3000w" class="image-77">
          <p class="paragraph-2 solution tech-process">Created a JSON file that contains the metadata required to store and <br>retrieve each clip within the video dialogue system</p><img src="../images/Screenshot-2022-11-08-at-6.10-1.png" loading="lazy" width="507" sizes="(max-width: 479px) 62vw, (max-width: 991px) 57vw, 507px" alt="" srcset="../images/Screenshot-2022-11-08-at-6.10-1-p-500.png 500w, ../images/Screenshot-2022-11-08-at-6.10-1-p-800.png 800w, ../images/Screenshot-2022-11-08-at-6.10-1-p-1080.png 1080w, ../images/Screenshot-2022-11-08-at-6.10-1-p-1600.png 1600w, ../images/Screenshot-2022-11-08-at-6.10-1-p-2000.png 2000w, ../images/Screenshot-2022-11-08-at-6.10-1-p-2600.png 2600w, ../images/Screenshot-2022-11-08-at-6.10-1.png 3000w" class="image-77">
          <p class="paragraph-2 solution tech-process">Scripted a file to upload multiple videos to TOIA via the command line. Additionally, I added a feature to enable uploading videos via drag and drop using the upload button.</p><img src="../images/group10.png" loading="lazy" width="507" sizes="(max-width: 479px) 62vw, (max-width: 991px) 57vw, 507px" alt="" srcset="../images/group10-p-500.png 500w, ../images/group10-p-800.png 800w, ../images/group10-p-1080.png 1080w, ../images/group10-p-1600.png 1600w, ../images/group10-p-2000.png 2000w, ../images/group10-p-2600.png 2600w, ../images/group10-p-3200.png 3200w, ../images/group10.png 4000w" class="image-77 no-gap">
        </div>
      </div>
    </div>
    <div class="make-learning-fun">
      <div class="div-block-49 quizmaze"></div>
    </div>
  </div>
  <div class="challenge solution special another">
    <div class="heading-jumbo-tiny">design and build<br>‍</div>
    <div class="div-block-52">
      <div class="div-block-48">
        <div class="text-block-28">Development of <br>Web Interface</div>
        <p class="paragraph-2 solution">For the system architecture, I focused on leveraging TOIA&#x27;s existing features, such as the use of an Automatic Speech Recognition (ASR) function to receive the user&#x27;s voice input, and a dialogue manager system that returns the most relevant video from the database based on the user&#x27;s utterances. Using these elements and the React.JS library, I designed and developed &quot;Elephant in the Room&quot; as illustrated below:<br><br>On the landing page (left), players are presented with choices and descriptions of streams to interact with. Upon clicking a specific topic, the player is directed to an interaction page where they can have conversations with videos in the database via text or voice (right).</p>
      </div><img src="../images/Group-22.jpg" loading="lazy" sizes="(max-width: 6863px) 80vw, 5491px" srcset="../images/Group-22-p-500.jpg 500w, ../images/Group-22-p-800.jpg 800w, ../images/Group-22-p-1080.jpg 1080w, ../images/Group-22-p-1600.jpg 1600w, ../images/Group-22-p-2000.jpg 2000w, ../images/Group-22-p-2600.jpg 2600w, ../images/Group-22-p-3200.jpg 3200w, ../images/Group-22.jpg 5491w" alt="">
    </div>
    <div class="div-block-52">
      <div class="div-block-48">
        <div class="text-block-28">Video Database Curation</div>
        <p class="paragraph-2 solution">While curating videos on the topic of death, I faced challenges such as a lack of content on such topic and the need to find specific Q&amp;A interview formats. However, I found selected videos such as &quot;Three Dying People Talk About Death&quot; by CUT, which featured three individuals diagnosed with chronic diseases, and &quot;Old(er) People Talk About Death,&quot; which featured Singaporean seniors sharing their thoughts on the finality of life, to be invaluable.<br><br>To create short clips of these videos, I used DaVinci Resolve and labeled each clip with question-answer pairs. These pairs were transformed into 1024-dimensional vector embeddings using the &#x27;text-search-ada-doc-001&#x27; model. The embeddings are then analyzed for similarity with user input and activated by the dialogue manager.</p>
      </div><img src="../images/Group-23.jpg" loading="lazy" sizes="(max-width: 2131px) 80vw, 1705px" srcset="../images/Group-23-p-500.jpg 500w, ../images/Group-23-p-800.jpg 800w, ../images/Group-23-p-1080.jpg 1080w, ../images/Group-23-p-1600.jpg 1600w, ../images/Group-23.jpg 1705w" alt="">
    </div>
    <div class="div-block-48">
      <div class="text-block-28">Dialogue Management</div>
      <p class="paragraph-2 solution">The system supports two types of interaction: text and voice. Users can type questions using the text input field or ask via voice, which is automatically converted into text using speech recognition technology. The input is then compared to vector embeddings, and the dialogue manager proposes the most accurate answer if the similarity between the user input and the video data is above 0.29. If the similarity is below this threshold, a video of the &quot;I don&#x27;t have an answer for that question&quot; type is returned instead. OpenAI&#x27;s GPT-3 models are used to perform the retrieval task.</p>
    </div><img src="../images/Screenshot-2023-05-31-at-2.08.04-PM.png" loading="lazy" sizes="(max-width: 1997px) 80vw, 1598px" srcset="../images/Screenshot-2023-05-31-at-2.08.04-PM-p-500.png 500w, ../images/Screenshot-2023-05-31-at-2.08.04-PM-p-800.png 800w, ../images/Screenshot-2023-05-31-at-2.08.04-PM-p-1080.png 1080w, ../images/Screenshot-2023-05-31-at-2.08.04-PM.png 1598w" alt="">
  </div>
  <div class="challenge solution special">
    <div class="heading-jumbo-tiny">user testing <br>‍</div>
    <div class="div-block-52">
      <div class="div-block-48">
        <div class="text-block-28">Round 1</div>
        <p class="paragraph-2 solution">After creating a &quot;Death&quot; discussion page with 62 videos, I conducted the first round of user testing to observe the types of questions users asked and their methods of interaction.</p>
      </div><img src="../images/user-testing1.jpg" loading="lazy" sizes="(max-width: 4646px) 80vw, 3717px" srcset="../images/user-testing1-p-500.jpg 500w, ../images/user-testing1-p-800.jpg 800w, ../images/user-testing1-p-1080.jpg 1080w, ../images/user-testing1-p-1600.jpg 1600w, ../images/user-testing1-p-2000.jpg 2000w, ../images/user-testing1-p-2600.jpg 2600w, ../images/user-testing1-p-3200.jpg 3200w, ../images/user-testing1.jpg 3717w" alt="">
      <div class="div-block-49 round1">
        <div class="div-block-48 round1">
          <div class="text-block-28">Iterations</div>
          <p class="paragraph-2 solution">First, users were drawn to click on name icons. To make it more interactive, I added a feature where hovering over an icon displays a one-line introduction of the character. Clicking on the icon allows users to interact with that specific person. For example, hovering over the Layla icon displays a one-liner description of her as &quot;a woman with end-stage renal disease.&quot; If clicked, Layla&#x27;s name is automatically added to the input, allowing users to interact with her videos.<br><br>Secondly, I noticed that users found it unintuitive to mute and unmute ASR using a button. To address this, I added a new feature where users can hold the spacebar to speak, similar to the voice message feature in social media.<br><br>Finally, I replaced the clickable question suggestion card with a simple question list. This list provides interesting prompts for users to ask themselves, making the interaction more engaging and solving the issue of making it seem less real-time.</p>
        </div><img src="../images/Group-13-1.jpg" loading="lazy" sizes="76vw" srcset="../images/Group-13-1-p-500.jpg 500w, ../images/Group-13-1-p-800.jpg 800w, ../images/Group-13-1-p-1080.jpg 1080w, ../images/Group-13-1-p-1600.jpg 1600w, ../images/Group-13-1.jpg 1800w" alt="" class="image-36 round1">
        <div class="div-block-98">
          <div class="text-block-46 round1">Before</div>
          <div class="text-block-46 round1 after">After</div>
        </div>
      </div>
    </div>
    <div class="div-block-48">
      <div class="text-block-28">Round 2</div>
      <p class="paragraph-2 solution">After creating a discussion page that covered topics such as birth, death, and sex, I conducted the second round of user testing. This time, the focus was on evaluating the quality of user interaction.</p>
    </div><img src="../images/Group-24.jpg" loading="lazy" sizes="80vw" srcset="../images/Group-24-p-500.jpg 500w, ../images/Group-24-p-800.jpg 800w, ../images/Group-24-p-1080.jpg 1080w, ../images/Group-24.jpg 1243w" alt="">
    <div class="div-block-49">
      <div class="div-block-48">
        <div class="text-block-28 progressindication">Iterations</div>
        <div class="div-block-99 w-clearfix">
          <p class="paragraph-2 solution"><strong>No-Answer Type Responses<br><br></strong>Users assumed that the system is broken if they ask a question and receive no answer. To address this issue, I have recorded &quot;No-Answer Type&quot; responses to provide an explanation for no retrieval.<br></p><img src="../images/Screenshot-2023-04-26-at-9.13-1.jpg" loading="lazy" sizes="(max-width: 991px) 44vw, 35vw" srcset="../images/Screenshot-2023-04-26-at-9.13-1-p-500.jpg 500w, ../images/Screenshot-2023-04-26-at-9.13-1-p-800.jpg 800w, ../images/Screenshot-2023-04-26-at-9.13-1-p-1080.jpg 1080w, ../images/Screenshot-2023-04-26-at-9.13-1-p-1600.jpg 1600w, ../images/Screenshot-2023-04-26-at-9.13-1.jpg 1802w" alt="" class="image-79">
          <p class="paragraph-2 solution"><strong>Deprioritize Already Played Videos<br><br></strong>The repetition of videos was a problem. The current answer retrieval system treats each input as independent of previously asked questions, so the same videos can be played consecutively. To address this issue, the dialogue manager was modified to cache the last 10 videos played and prioritize answers that do not involve these videos.<br>The cache is cleared every 15 minutes, which is the expected interaction time per person for one topic.<br></p><img src="../images/Screenshot-2023-03-26-at-5.22-1.jpg" loading="lazy" sizes="(max-width: 991px) 44vw, 35vw" srcset="../images/Screenshot-2023-03-26-at-5.22-1-p-500.jpg 500w, ../images/Screenshot-2023-03-26-at-5.22-1-p-800.jpg 800w, ../images/Screenshot-2023-03-26-at-5.22-1-p-1080.jpg 1080w, ../images/Screenshot-2023-03-26-at-5.22-1.jpg 1578w" alt="" class="image-79">
          <p class="paragraph-2 solution"><strong>Physical Cards<br><br></strong>Recognizing that users struggle to come up with questions that can spark interesting conversations, I created a physical deck of cards that can help delve deeper into conversations.<br></p><img src="../images/Screenshot-2023-04-29-at-10.42-1.jpg" loading="lazy" sizes="(max-width: 991px) 44vw, 35vw" srcset="../images/Screenshot-2023-04-29-at-10.42-1-p-500.jpg 500w, ../images/Screenshot-2023-04-29-at-10.42-1-p-800.jpg 800w, ../images/Screenshot-2023-04-29-at-10.42-1-p-1080.jpg 1080w, ../images/Screenshot-2023-04-29-at-10.42-1-p-1600.jpg 1600w, ../images/Screenshot-2023-04-29-at-10.42-1.jpg 1643w" alt="" class="image-79">
        </div>
      </div>
    </div>
  </div>
  <div class="challenge solution special">
    <div class="heading-jumbo-tiny">installation &amp; exhibition <br>‍</div>
    <div class="div-block-52">
      <div class="div-block-48">
        <div class="text-block-28">Location Scouting</div>
        <p class="paragraph-2 solution">Elephant in the Room is housed in a private booth. While scouting for a location, I came across Professor Laura Schneider&#x27;s no-longer-used telephone-booth-like structure, which she had previously used for her &quot;Earliest Memory Archive&quot; project. </p>
      </div><img src="../images/Group-199.jpg" loading="lazy" sizes="(max-width: 3527px) 80vw, 2822px" srcset="../images/Group-199-p-500.jpg 500w, ../images/Group-199-p-800.jpg 800w, ../images/Group-199-p-1080.jpg 1080w, ../images/Group-199-p-1600.jpg 1600w, ../images/Group-199-p-2000.jpg 2000w, ../images/Group-199-p-2600.jpg 2600w, ../images/Group-199.jpg 2822w" alt="" class="image-78">
      <div class="div-block-48">
        <div class="text-block-28">Setup</div>
        <p class="paragraph-2 solution">After successfully deploying the locally hosted project online, I connected a Mac mini to power the system and set up keyboard, microphone, and mouse for users to navigate the screen and interact.</p>
      </div><img src="../images/Group-200.jpg" loading="lazy" sizes="(max-width: 3947px) 80vw, 3158px" srcset="../images/Group-200-p-500.jpg 500w, ../images/Group-200-p-800.jpg 800w, ../images/Group-200-p-1080.jpg 1080w, ../images/Group-200-p-1600.jpg 1600w, ../images/Group-200-p-2000.jpg 2000w, ../images/Group-200-p-2600.jpg 2600w, ../images/Group-200.jpg 3158w" alt="" class="image-78">
      <div class="div-block-48">
        <div class="text-block-28">Content Warning</div>
        <p class="paragraph-2 solution">It was important to consider the potential impact of the content on visitors. Conversations about death, sex, and birth can be triggering for some individuals. After seeking cultural advice, I decided to create a friendly content warning sign to display outside the booth.</p>
      </div><img src="../images/Group-34.jpg" loading="lazy" sizes="(max-width: 4282px) 80vw, 3426px" srcset="../images/Group-34-p-500.jpg 500w, ../images/Group-34-p-800.jpg 800w, ../images/Group-34-p-1080.jpg 1080w, ../images/Group-34-p-1600.jpg 1600w, ../images/Group-34-p-2000.jpg 2000w, ../images/Group-34-p-2600.jpg 2600w, ../images/Group-34-p-3200.jpg 3200w, ../images/Group-34.jpg 3426w" alt="" class="image-78">
      <div class="div-block-48">
        <div class="text-block-28">Video Instruction</div>
        <p class="paragraph-2 solution">On the opening day, I found myself having to convince people to “Talk” to videos. To address this, I created a how-to video that plays in a loop. First-time visitors to the booth can watch this video and quickly understand how to use the new video technologies that allow them to converse with videos.</p>
      </div><img src="../images/Group-35.png" loading="lazy" sizes="(max-width: 2186px) 80vw, 1749px" srcset="../images/Group-35-p-500.png 500w, ../images/Group-35-p-800.png 800w, ../images/Group-35-p-1080.png 1080w, ../images/Group-35-p-1600.png 1600w, ../images/Group-35.png 1749w" alt="" class="image-78"><img src="../images/Screenshot-2023-05-31-at-12.11.48-PM.png" loading="lazy" sizes="80vw" srcset="../images/Screenshot-2023-05-31-at-12.11.48-PM-p-500.png 500w, ../images/Screenshot-2023-05-31-at-12.11.48-PM-p-800.png 800w, ../images/Screenshot-2023-05-31-at-12.11.48-PM-p-1080.png 1080w, ../images/Screenshot-2023-05-31-at-12.11.48-PM.png 1160w" alt="" class="image-78">
    </div>
  </div>
  <div class="challenge reflection">
    <div class="div-block-48">
      <div class="text-block-28 progressindication">Reflection</div>
      <p class="paragraph-2 solution">
        <strong>Truly Cutting-Edge, Deeply Human<br><br></strong>
        Despite being a highly technical project powered by machine learning and artificial intelligence technology, <em>Elephant in the Room</em> has deepened my understanding of human thought, communication, and connection.<br><br>
        <strong>Inclusiveness and Knowledge Gap in the World of AI<br>‍<br></strong>
        Although I strived to include a range of perspectives from individuals of different races, stages of life, and experiences when curating videos, the opinions shared in the stream are predominantly from English-speaking individuals from financially comfortable backgrounds. This lack of diversity limits the range of perspectives. Additionally, the focus of AI on facilitating English conversations has highlighted a growing knowledge gap between English speakers and non-English speakers.<br><br>
        <strong>Compassionate Artificial Intelligence<br><br></strong>
        Amit Ray, the author of <em>Compassionate Artificial Intelligence</em>, notes that "as more and more artificial intelligence enters the world, more and more emotional intelligence must enter into leadership" (Ray). <em>Elephant in the Room</em> resonates with this belief. By using cutting-edge AI technology, it fosters compassionate and long-overdue conversations that are often avoided, addressing one "elephant in the room" at a time.<br><br>
        <strong>Full Integration into YouTube<br>‍<br></strong>
        Looking ahead, I aim to create a fully integrated system that retrieves relevant sections of videos directly from YouTube based on user input. Users will be able to ask questions and receive answers from a large YouTube database through a search process similar to Google search, thus broadening the scope of conversation. Achieving this will involve tackling challenging tasks in natural language processing (NLP), such as argument mining.<br>‍
        <strong>LinkedIn Interactive Biography<br>‍<br></strong>
        This technology is not only suitable for artistic purposes but also has commercial applications, such as integration into LinkedIn profiles. For instance, instead of merely reading a few lines of description or viewing a profile image, this technology could enable users to conduct interviews directly on LinkedIn.
      </p>
    </div>
  </div>
  
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=61d8ff5e7050560d28f3e298" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="../js/webflow.js" type="text/javascript"></script>
</body>
</html>